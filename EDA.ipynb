{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Quality Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be attempting to improve model quality by check alternative routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import ace_tools as tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2350214200.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\alexi\\Desktop\\Coding Projects\\Churn-Project\\Churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i checked for anomalies and we seem to have a column (Tenure) with missing values but our data types seem fine so ill check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>7847</td>\n",
       "      <td>15755416</td>\n",
       "      <td>Hart</td>\n",
       "      <td>557</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87739.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>123096.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2604</td>\n",
       "      <td>15583049</td>\n",
       "      <td>Wallace</td>\n",
       "      <td>643</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160426.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>188533.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>2639</td>\n",
       "      <td>15698619</td>\n",
       "      <td>Bowhay</td>\n",
       "      <td>593</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76357.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>4906</td>\n",
       "      <td>15627999</td>\n",
       "      <td>Kung</td>\n",
       "      <td>590</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83090.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>6440</td>\n",
       "      <td>15583371</td>\n",
       "      <td>Artemiev</td>\n",
       "      <td>632</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138207.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60778.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>6656</td>\n",
       "      <td>15703763</td>\n",
       "      <td>Sanderson</td>\n",
       "      <td>554</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85304.27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58076.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>3416</td>\n",
       "      <td>15710689</td>\n",
       "      <td>Angel</td>\n",
       "      <td>578</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63609.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74965.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>9926</td>\n",
       "      <td>15605672</td>\n",
       "      <td>Yuan</td>\n",
       "      <td>694</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195926.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85522.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>571</td>\n",
       "      <td>15728505</td>\n",
       "      <td>Ts'ao</td>\n",
       "      <td>601</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100486.18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62678.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>5414</td>\n",
       "      <td>15588918</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>671</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197202.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>577</td>\n",
       "      <td>15761986</td>\n",
       "      <td>Obialo</td>\n",
       "      <td>439</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138901.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75685.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>2898</td>\n",
       "      <td>15664150</td>\n",
       "      <td>Holland</td>\n",
       "      <td>528</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170214.23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49284.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>5105</td>\n",
       "      <td>15694349</td>\n",
       "      <td>Ngozichukwuka</td>\n",
       "      <td>714</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6923.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>616</td>\n",
       "      <td>15745295</td>\n",
       "      <td>Gether</td>\n",
       "      <td>727</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121751.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>15721181</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>611</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45886.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>8802</td>\n",
       "      <td>15606115</td>\n",
       "      <td>P'eng</td>\n",
       "      <td>510</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191665.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131312.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>4261</td>\n",
       "      <td>15664555</td>\n",
       "      <td>Hughes</td>\n",
       "      <td>587</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>106174.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>5515</td>\n",
       "      <td>15773283</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>641</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38340.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32607.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7734</th>\n",
       "      <td>7735</td>\n",
       "      <td>15722473</td>\n",
       "      <td>Faulkner</td>\n",
       "      <td>713</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55772.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>4793</td>\n",
       "      <td>15809991</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>756</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130274.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133535.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId        Surname  CreditScore Geography  Gender  \\\n",
       "7846       7847    15755416           Hart          557    France  Female   \n",
       "2603       2604    15583049        Wallace          643   Germany  Female   \n",
       "2638       2639    15698619         Bowhay          593    France    Male   \n",
       "4905       4906    15627999           Kung          590     Spain    Male   \n",
       "6439       6440    15583371       Artemiev          632     Spain    Male   \n",
       "6655       6656    15703763      Sanderson          554    France    Male   \n",
       "3415       3416    15710689          Angel          578     Spain    Male   \n",
       "9925       9926    15605672           Yuan          694    France  Female   \n",
       "570         571    15728505          Ts'ao          601    France    Male   \n",
       "5413       5414    15588918       Mitchell          671    France  Female   \n",
       "576         577    15761986         Obialo          439     Spain  Female   \n",
       "2897       2898    15664150        Holland          528   Germany  Female   \n",
       "5104       5105    15694349  Ngozichukwuka          714     Spain    Male   \n",
       "615         616    15745295         Gether          727     Spain  Female   \n",
       "386         387    15721181         Oliver          611     Spain    Male   \n",
       "8801       8802    15606115          P'eng          510    France  Female   \n",
       "4260       4261    15664555         Hughes          587    France    Male   \n",
       "5514       5515    15773283         Dennis          641    France    Male   \n",
       "7734       7735    15722473       Faulkner          713    France    Male   \n",
       "4792       4793    15809991        Ferrari          756     Spain    Male   \n",
       "\n",
       "      Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "7846   27     NaN   87739.08              1          1               1   \n",
       "2603   34     NaN  160426.07              1          0               1   \n",
       "2638   43     NaN       0.00              2          1               1   \n",
       "4905   30     NaN       0.00              2          1               0   \n",
       "6439   37     NaN  138207.08              1          1               0   \n",
       "6655   44     NaN   85304.27              1          1               1   \n",
       "3415   40     NaN   63609.92              1          0               0   \n",
       "9925   38     NaN  195926.39              1          1               1   \n",
       "570    44     NaN  100486.18              2          1               1   \n",
       "5413   42     NaN       0.00              2          1               0   \n",
       "576    32     NaN  138901.61              1          1               0   \n",
       "2897   29     NaN  170214.23              2          1               0   \n",
       "5104   44     NaN       0.00              1          0               1   \n",
       "615    31     NaN       0.00              1          1               0   \n",
       "386    46     NaN       0.00              2          1               0   \n",
       "8801   52     NaN  191665.21              1          1               1   \n",
       "4260   40     NaN       0.00              4          0               1   \n",
       "5514   65     NaN   38340.02              1          1               0   \n",
       "7734   41     NaN       0.00              2          1               0   \n",
       "4792   19     NaN  130274.22              1          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "7846        123096.56       0  \n",
       "2603        188533.11       0  \n",
       "2638         76357.43       0  \n",
       "4905         83090.35       0  \n",
       "6439         60778.11       1  \n",
       "6655         58076.52       0  \n",
       "3415         74965.61       1  \n",
       "9925         85522.84       0  \n",
       "570          62678.53       0  \n",
       "5413        197202.48       0  \n",
       "576          75685.97       0  \n",
       "2897         49284.00       0  \n",
       "5104          6923.11       0  \n",
       "615         121751.04       1  \n",
       "386          45886.33       0  \n",
       "8801        131312.56       1  \n",
       "4260        106174.70       1  \n",
       "5514         32607.77       1  \n",
       "7734         55772.04       0  \n",
       "4792        133535.29       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = data[data.isnull().any(axis=1)]\n",
    "missing_values.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created a missing value dataframe to access the missing values better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30      1\n",
       "48      0\n",
       "51      0\n",
       "53      1\n",
       "60      0\n",
       "       ..\n",
       "9944    0\n",
       "9956    1\n",
       "9964    0\n",
       "9985    0\n",
       "9999    0\n",
       "Name: Exited, Length: 909, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 2 cells above were to test if there is a correlation with the exited customers and the missing values and i dont believe there is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsActiveMember\n",
       "1    464\n",
       "0    445\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values['IsActiveMember'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tested if it had anyhting to do with their activeness and after running this i dont believe there is another patter or correlation to be made it is also too much data to lose so i will fill the value with 0 as i think it could indicate newer accounts or simply ones that havent been active for more than a year and as the test is to see customer turnover it could be useful information later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tenure']  = data['Tenure'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Values have been filled and i can work with the data now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and Calculating With Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    79.63\n",
       "1    20.37\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = data['Exited'].value_counts(normalize=True) * 100\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are highly imbalanced as the target is not closer to even with the in this case feature so it might favor the majority in our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8715179079022172,\n",
       "  'recall': 0.9623352165725048,\n",
       "  'f1-score': 0.9146778042959427,\n",
       "  'support': 1593.0},\n",
       " '1': {'precision': 0.7510373443983402,\n",
       "  'recall': 0.44471744471744473,\n",
       "  'f1-score': 0.558641975308642,\n",
       "  'support': 407.0},\n",
       " 'accuracy': 0.857,\n",
       " 'macro avg': {'precision': 0.8112776261502788,\n",
       "  'recall': 0.7035263306449747,\n",
       "  'f1-score': 0.7366598898022924,\n",
       "  'support': 2000.0},\n",
       " 'weighted avg': {'precision': 0.8470001132291781,\n",
       "  'recall': 0.857,\n",
       "  'f1-score': 0.8422245130970271,\n",
       "  'support': 2000.0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Categorical Data\n",
    "encode_geo = LabelEncoder()\n",
    "encode_gender = LabelEncoder()\n",
    "\n",
    "data['Geography'] = encode_geo.fit_transform(data['Geography'])\n",
    "data['Gender'] = encode_gender.fit_transform(data['Gender'])\n",
    "\n",
    "# Feature and Target\n",
    "features = data.drop(columns=['Exited', 'Surname'])\n",
    "target = data['Exited']\n",
    "\n",
    "# Splitting Data into Training and Test\n",
    "x = features\n",
    "y = target\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=50, stratify=y)\n",
    "\n",
    "# Standardize the Features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# RandomForest Model Imbalanced Training\n",
    "model = RandomForestClassifier(random_state=50)\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "# Evaluating the Model\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to run a classification report for a more detailed list of what we are looking at and its returned some useful information when the model predicts 0 (non-Exited) it is fairly accurate the model successfully identified ~96% of the class and when it does predict 0 it is 87% accurate and a 91% f1 or overall performance for that class however when tasked with identifying 1(exiters) it performs poorly identifying only ~44% of the class with a 75% precision so when it does predict is is fairly accurate the f1_score being a ~55% showing a need for improvement in this class most likely due to the imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing, Choosing Best Model, and Hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing and Model Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "               precision    recall  f1-score    support\n",
      "0              0.913502  0.815443  0.861692  1593.0000\n",
      "1              0.491349  0.697789  0.576650   407.0000\n",
      "accuracy       0.791500  0.791500  0.791500     0.7915\n",
      "macro avg      0.702426  0.756616  0.719171  2000.0000\n",
      "weighted avg   0.827594  0.791500  0.803686  2000.0000\n",
      "\n",
      "Logistic Regression Results:\n",
      "               precision    recall  f1-score   support\n",
      "0              0.889103  0.578782  0.701141  1593.000\n",
      "1              0.303219  0.717445  0.426277   407.000\n",
      "accuracy       0.607000  0.607000  0.607000     0.607\n",
      "macro avg      0.596161  0.648113  0.563709  2000.000\n",
      "weighted avg   0.769876  0.607000  0.645206  2000.000\n",
      "\n",
      "Decision Tree Results:\n",
      "               precision    recall  f1-score    support\n",
      "0              0.895631  0.694915  0.782609  1593.0000\n",
      "1              0.363874  0.683047  0.474808   407.0000\n",
      "accuracy       0.692500  0.692500  0.692500     0.6925\n",
      "macro avg      0.629753  0.688981  0.628708  2000.0000\n",
      "weighted avg   0.787419  0.692500  0.719971  2000.0000\n"
     ]
    }
   ],
   "source": [
    "# Applying SMOTE for Oversample\n",
    "smote = SMOTE(random_state=50)\n",
    "x_train_rescale, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Scaling for Resample\n",
    "x_resample_scaled = scaler.fit_transform(x_train_rescale)\n",
    "\n",
    "# Balancing Models \n",
    "rf_model = RandomForestClassifier(class_weight=\"balanced\", random_state=50)\n",
    "log_reg_model = LogisticRegression(class_weight=\"balanced\",max_iter=1000, random_state=50)\n",
    "dt_model = DecisionTreeClassifier(class_weight=\"balanced\", random_state=50)\n",
    "\n",
    "# Train Models\n",
    "rf_model.fit(x_resample_scaled, y_train_smote)\n",
    "log_reg_model.fit(x_resample_scaled, y_train_smote)\n",
    "dt_model.fit(x_resample_scaled, y_train_smote)\n",
    "\n",
    "# Make Predictions\n",
    "rf_pred = rf_model.predict(x_test_scaled)\n",
    "log_reg_pred = log_reg_model.predict(x_test_scaled)\n",
    "dt_pred = dt_model.predict(x_test_scaled)\n",
    "\n",
    "# Evaluate Models\n",
    "rf_report = classification_report(y_test, rf_pred, output_dict=True)\n",
    "log_reg_report = classification_report(y_test, log_reg_pred, output_dict=True)\n",
    "dt_report = classification_report(y_test, dt_pred, output_dict=True)\n",
    "\n",
    "# Convert to DF For Easy Comparison\n",
    "rf_df = pd.DataFrame(rf_report).transpose()\n",
    "log_reg_df = pd.DataFrame(log_reg_report).transpose()\n",
    "dt_df = pd.DataFrame(dt_report).transpose()\n",
    "\n",
    "print(\"Random Forest Results:\\n\", rf_df)\n",
    "print(\"\\nLogistic Regression Results:\\n\", log_reg_df)\n",
    "print(\"\\nDecision Tree Results:\\n\", dt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applyed SMOTE for oversampling as it made more sense than just duplicating some of the other rows as it creates 'synthetic' rows. Scaled the Resample. Balanced all 3 Models with. Trained all 3 Models. Ran a classification report and converted it to a dataframe for ease of access. The results were very telling of all 3 models for what we are looking for which is a consistent way to predict churn rate although logistic has the highest recall it just wasnt accurate enough leaving random forest as out best option with a recall of 69% slightly lower than the 71% from logistic but also a ~49% precision which is almost 20% higher it also proves to be the balanaced approach and we will improve upon it with hyperparamters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909972</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.865328</td>\n",
       "      <td>1593.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498201</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.575286</td>\n",
       "      <td>407.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.795500</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>0.7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.704087</td>\n",
       "      <td>0.752724</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.826177</td>\n",
       "      <td>0.795500</td>\n",
       "      <td>0.806304</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.909972  0.824859  0.865328  1593.0000\n",
       "1              0.498201  0.680590  0.575286   407.0000\n",
       "accuracy       0.795500  0.795500  0.795500     0.7955\n",
       "macro avg      0.704087  0.752724  0.720307  2000.0000\n",
       "weighted avg   0.826177  0.795500  0.806304  2000.0000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform RandomSearchCV for Best Parameters\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    random_state=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Model\n",
    "rf_search.fit(x_resample_scaled, y_train_smote)\n",
    "\n",
    "# Best Params\n",
    "best_params = rf_search.best_params_\n",
    "\n",
    "# Train Best rf Model\n",
    "best_rf_model = RandomForestClassifier(**best_params, class_weight='balanced', random_state=50)\n",
    "best_rf_model.fit(x_resample_scaled, y_train_smote)\n",
    "\n",
    "# Predict, Evaluate, Report\n",
    "best_rf_pred = best_rf_model.predict(x_test_scaled)\n",
    "best_rf_report = classification_report(y_test, best_rf_pred, output_dict=True)\n",
    "best_rf_df = pd.DataFrame(best_rf_report).transpose()\n",
    "\n",
    "# Print\n",
    "print(\"Best RandomForest Results:\")\n",
    "best_rf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set up Parameters and used randomsearchcv to find the best parameters for the rf model and we see marginal success with this as accuracy and precision slightly increase but we see a slight decrease in recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized Random Forest model strikes a solid balance between accuracy (79.55%), precision (49.82%), and recall (68.06%), making it a reliable tool for predicting customer churn. Initially, it struggled with false positives and missed churn cases, but SMOTE helped balance the dataset, and class weighting made churn cases more significant. After fine-tuning with hyperparameter optimization, the model became more precise while still identifying a good portion of churners. While it’s now a bit more selective, it does a better job at reducing misclassification errors. Overall, this version is the best so far, but there’s room for improvement—adjusting the decision threshold, testing XGBoost or LightGBM, or analyzing feature importance could take it even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
